{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a28beff4-d02f-4d6a-8e63-96638406a546",
   "metadata": {},
   "source": [
    "# Донка v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f366e42-f0b5-47da-83ec-e6097e0c02e1",
   "metadata": {},
   "source": [
    "Seq2Seq Transformer трениран на околу 500.000 реченици"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c398c70e-9175-4d24-b372-d5080cb79ced",
   "metadata": {},
   "source": [
    "Прочитајте повеќе на блогот:[Имплементациjа На Трансформер Архитектурата За Македонско-Англиски Превод На Реченици](https://najdovski-stefan.github.io/basics/2025/06/06/transformer-mk-en.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344ff91e-27c6-41f2-b166-52304dd0daa3",
   "metadata": {},
   "source": [
    "Преведува кратки и едноствни македонски реченици во англиски реченици"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9426b1bb-75b9-4729-bf30-04a38244e608",
   "metadata": {},
   "source": [
    "Доколку сакате локално да тестирате потребно ви е Python 3.10.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6427812-6838-4172-85f5-0a92ab9be2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Локално\n",
    "!pip install torch==2.2.2 torchtext==0.17.2\n",
    "!pip install \"numpy<2\"\n",
    "!pip install pandas sentencepiece matplotlib sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e11d11-22e0-4f18-83d0-ede1c303130f",
   "metadata": {},
   "source": [
    "Потребни библиотеки, на крајот враќа на што се извршува, функционира доволно брзо и на cpu и на cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372c79b0-f996-41e0-b659-f69429d880ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torchtext\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "from torch.nn import TransformerEncoder, TransformerDecoder, TransformerEncoderLayer, TransformerDecoderLayer\n",
    "import io\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sentencepiece as spm\n",
    "torch.manual_seed(0)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61e3da7-ed03-4026-bc8d-044e9e823f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spm_vocab(filepath, max_size=None):\n",
    "    vocab = []\n",
    "    with open(filepath, encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            token = line.strip().split('\\t')[0]\n",
    "            vocab.append(token)\n",
    "            if max_size and len(vocab) >= max_size:\n",
    "                break\n",
    "    return vocab\n",
    "\n",
    "mk_model_path = \"spm.mk.full.model\"\n",
    "en_model_path = \"spm.en.full.model\"\n",
    "mk_vocab = load_spm_vocab('spm.mk.full.vocab')\n",
    "en_vocab = load_spm_vocab('spm.en.full.vocab')\n",
    "\n",
    "en_tokenizer = spm.SentencePieceProcessor(model_file=en_model_path)\n",
    "mk_tokenizer = spm.SentencePieceProcessor(model_file=mk_model_path)\n",
    "\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, num_encoder_layers: int, num_decoder_layers: int,\n",
    "                 emb_size: int, src_vocab_size: int, tgt_vocab_size: int,\n",
    "                 dim_feedforward:int = 512, dropout:float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        encoder_layer = TransformerEncoderLayer(d_model=emb_size, nhead=NHEAD,\n",
    "                                                dim_feedforward=dim_feedforward)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        decoder_layer = TransformerDecoderLayer(d_model=emb_size, nhead=NHEAD,\n",
    "                                                dim_feedforward=dim_feedforward)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
    "\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self, src: Tensor, trg: Tensor, src_mask: Tensor,\n",
    "                tgt_mask: Tensor, src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor, memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        memory = self.transformer_encoder(src_emb, src_mask, src_padding_mask)\n",
    "        outs = self.transformer_decoder(tgt_emb, memory, tgt_mask, None,\n",
    "                                        tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer_encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer_decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)\n",
    "\n",
    "        \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emb_size: int, dropout, maxlen: int = 10000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(1) \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding +\n",
    "                            self.pos_embedding[:token_embedding.size(0),:])\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "  src_seq_len = src.shape[0]\n",
    "  tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "  tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "  src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.bool)\n",
    "\n",
    "  src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "  tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "  return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
    "\n",
    "\n",
    "SRC_VOCAB_SIZE = len(mk_vocab)\n",
    "TGT_VOCAB_SIZE = len(en_vocab)\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 4\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "NUM_EPOCHS = 18\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS,\n",
    "                                 EMB_SIZE, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE,\n",
    "                                 FFN_HID_DIM)\n",
    "\n",
    "\n",
    "model = transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS,\n",
    "                                 EMB_SIZE, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE,\n",
    "                                 FFN_HID_DIM)\n",
    "model.to(DEVICE)\n",
    "\n",
    "# ID\n",
    "PAD_IDX = mk_vocab.index('<pad>')\n",
    "BOS_IDX = mk_vocab.index('<s>')\n",
    "EOS_IDX = mk_vocab.index('</s>')\n",
    "\n",
    "model = Seq2SeqTransformer(\n",
    "    NUM_ENCODER_LAYERS,\n",
    "    NUM_DECODER_LAYERS,\n",
    "    EMB_SIZE,\n",
    "    SRC_VOCAB_SIZE,\n",
    "    TGT_VOCAB_SIZE,\n",
    "    FFN_HID_DIM\n",
    ")\n",
    "model.to(DEVICE)\n",
    "\n",
    "checkpoint = torch.load('donka-v1_checkpoint_epoch18.pt', map_location=DEVICE)\n",
    "transformer.load_state_dict(checkpoint['model_state_dict'])\n",
    "transformer.eval()\n",
    "\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        memory_mask = torch.zeros(ys.shape[0], memory.shape[0]).to(DEVICE).type(torch.bool)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "          break\n",
    "    return ys\n",
    "\n",
    "def translate(model, src, src_vocab, tgt_vocab, src_tokenizer):\n",
    "    model.eval()\n",
    "    src = src.lower()\n",
    "    tokens = [BOS_IDX] + src_tokenizer.encode(src) + [EOS_IDX]\n",
    "    num_tokens = len(tokens)\n",
    "    src = torch.LongTensor(tokens).reshape(num_tokens, 1)\n",
    "    src_mask = torch.zeros(num_tokens, num_tokens).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(model, src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    decoded_tokens = [tgt_vocab[tok] for tok in tgt_tokens if tok < len(tgt_vocab)]\n",
    "    text = \" \".join(decoded_tokens)\n",
    "    text = text.replace(\"<s>\", \"\").replace(\"</s>\", \"\")\n",
    "    text = text.replace(\"▁\", \" \")\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c0c0af-33be-40f1-a80c-7c866bca00e5",
   "metadata": {},
   "source": [
    "## Слободно промени некои реченици за да тестираш"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa736c55-6501-48a3-a6fc-ad809fe0d2b1",
   "metadata": {},
   "source": [
    "Се што ви е потрбно е речениците да бидат сите со мали букви"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a578ee21-2cd8-4570-8e62-6279728cd1d3",
   "metadata": {},
   "source": [
    "Примери:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3604ab6-cc49-4448-882e-f3ff3fb00468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i  know  how  to  read  macedonian\n",
      "he  is  from  macedonia\n",
      "they  are  from  bitola\n",
      "we  are  students  of  fi c t  bitola\n",
      "drop  by  drop  lake\n",
      "the  man  study  as  alive\n",
      "while  he  is  alive\n"
     ]
    }
   ],
   "source": [
    "print(translate(transformer, \"јас знам да читам македонски\", mk_vocab, en_vocab, mk_tokenizer))\n",
    "print(translate(transformer, \"тој е од македонија\", mk_vocab, en_vocab, mk_tokenizer))\n",
    "print(translate(transformer, \"тие се од Битола\", mk_vocab, en_vocab, mk_tokenizer))\n",
    "print(translate(transformer, \"ние сме студенти на фикт битола\", mk_vocab, en_vocab, mk_tokenizer))\n",
    "print(translate(transformer, \"капка по капка езеро\", mk_vocab, en_vocab, mk_tokenizer))\n",
    "print(translate(transformer, \"човекот учи додека е жив\", mk_vocab, en_vocab, mk_tokenizer))\n",
    "print(translate(transformer, \"додека е жив тој учи\", mk_vocab, en_vocab, mk_tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3198a5f8-9449-4901-b8d4-3c13e203e6ed",
   "metadata": {},
   "source": [
    "## Функционира и со подолги реченици, проблемот е што е полош\n",
    "## Data set-от има bias (поголемиот дел од речениците се околу 10тина зборови) и очекува реченици до 10 збора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5cdfd6ef-8169-445c-8d5b-b834020099c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i  work  and  with  longer  text s ,  but  i  understand  very  worse\n"
     ]
    }
   ],
   "source": [
    "print(translate(transformer, \"работам и со подолги текстови, ама многу полошо разбирам\", mk_vocab, en_vocab, mk_tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d284e6a-2665-496d-8844-3838fe0a17b0",
   "metadata": {},
   "source": [
    "## Пробај твој реченици тука:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8095d9-6391-4964-b149-83c78a178059",
   "metadata": {},
   "source": [
    "Стави реченица на македонски помеѓу наводниците"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce6f964d-840f-44de-9605-44fb018de274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(translate(transformer, \"\", mk_vocab, en_vocab, mk_tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
